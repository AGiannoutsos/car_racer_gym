{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Copy of reinforcement_q_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vZq4VjDqVrms"
      ]
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "468867151d0449d083616ee2d3c21978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e1d263a4f1d49e1a6148823d3d16dfa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b282dee54624867b827d59152a853f7",
              "IPY_MODEL_674b5dd08fff481d88688cbf715441a0"
            ]
          }
        },
        "5e1d263a4f1d49e1a6148823d3d16dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b282dee54624867b827d59152a853f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_e658c75b9d6c4598a45ea69b7a9e52b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ab710871abd4fbb9d228a311d0ee390"
          }
        },
        "674b5dd08fff481d88688cbf715441a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7215d63d69a4f3b8bc1c43c31ae7397",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cf2a659e1ca4883a20b82f1a7f9daeb"
          }
        },
        "e658c75b9d6c4598a45ea69b7a9e52b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ab710871abd4fbb9d228a311d0ee390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7215d63d69a4f3b8bc1c43c31ae7397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cf2a659e1ca4883a20b82f1a7f9daeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d74dbc21f6a74b118728588f03cfbb93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_05ec633391c544dc914bb14e0f4b5879",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd9972aaeb154e0d889a035fafad48f8",
              "IPY_MODEL_667ed7b7be5c44d293ab87e798086993"
            ]
          }
        },
        "05ec633391c544dc914bb14e0f4b5879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd9972aaeb154e0d889a035fafad48f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_233b81de5b4c46d690ef011db8042583",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e7c3b4c79294ee4ae87407ea0cfe09c"
          }
        },
        "667ed7b7be5c44d293ab87e798086993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_53a0ed84b7dd41e7ae6bb83ae2347bde",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_583a4db6d9074477b2930a37d49707e6"
          }
        },
        "233b81de5b4c46d690ef011db8042583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e7c3b4c79294ee4ae87407ea0cfe09c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53a0ed84b7dd41e7ae6bb83ae2347bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "583a4db6d9074477b2930a37d49707e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "30O9g6JfcRWz"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0yIFeqjcRXB"
      },
      "source": [
        "\n",
        "Reinforcement Learning (DQN) Tutorial\n",
        "=====================================\n",
        "**Author**: `Adam Paszke <https://github.com/apaszke>`_\n",
        "\n",
        "\n",
        "This tutorial shows how to use PyTorch to train a Deep Q Learning (DQN) agent\n",
        "on the CartPole-v0 task from the `OpenAI Gym <https://gym.openai.com/>`__.\n",
        "\n",
        "**Task**\n",
        "\n",
        "The agent has to decide between two actions - moving the cart left or\n",
        "right - so that the pole attached to it stays upright. You can find an\n",
        "official leaderboard with various algorithms and visualizations at the\n",
        "`Gym website <https://gym.openai.com/envs/CartPole-v0>`__.\n",
        "\n",
        ".. figure:: /_static/img/cartpole.gif\n",
        "   :alt: cartpole\n",
        "\n",
        "   cartpole\n",
        "\n",
        "As the agent observes the current state of the environment and chooses\n",
        "an action, the environment *transitions* to a new state, and also\n",
        "returns a reward that indicates the consequences of the action. In this\n",
        "task, rewards are +1 for every incremental timestep and the environment\n",
        "terminates if the pole falls over too far or the cart moves more then 2.4\n",
        "units away from center. This means better performing scenarios will run\n",
        "for longer duration, accumulating larger return.\n",
        "\n",
        "The CartPole task is designed so that the inputs to the agent are 4 real\n",
        "values representing the environment state (position, velocity, etc.).\n",
        "However, neural networks can solve the task purely by looking at the\n",
        "scene, so we'll use a patch of the screen centered on the cart as an\n",
        "input. Because of this, our results aren't directly comparable to the\n",
        "ones from the official leaderboard - our task is much harder.\n",
        "Unfortunately this does slow down the training, because we have to\n",
        "render all the frames.\n",
        "\n",
        "Strictly speaking, we will present the state as the difference between\n",
        "the current screen patch and the previous one. This will allow the agent\n",
        "to take the velocity of the pole into account from one image.\n",
        "\n",
        "**Packages**\n",
        "\n",
        "\n",
        "First, let's import needed packages. Firstly, we need\n",
        "`gym <https://gym.openai.com/docs>`__ for the environment\n",
        "(Install using `pip install gym`).\n",
        "We'll also use the following from PyTorch:\n",
        "\n",
        "-  neural networks (``torch.nn``)\n",
        "-  optimization (``torch.optim``)\n",
        "-  automatic differentiation (``torch.autograd``)\n",
        "-  utilities for vision tasks (``torchvision`` - `a separate\n",
        "   package <https://github.com/pytorch/vision>`__).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXLEWcW9_mGv"
      },
      "source": [
        "%%capture\n",
        "!sudo apt update && sudo apt install python-opengl\n",
        "!sudo apt update && sudo apt install xvfb\n",
        "!pip install gym-notebook-wrapper stable-baselines[mpi] box2d box2d-kengz pyvirtualdisplay pyglet\n",
        "!pip install gym\n",
        "!pip install wandb\n",
        "!pip install gym pyvirtualdisplay -qq\n",
        "!pip install folium==0.2.1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg -qq\n",
        "project=\"gym_car_racer\"\n",
        "entity=\"andreas_giannoutsos\"\n",
        "import wandb\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5BmHLRuAXyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a4ff13-0401-4bfd-b8ab-627ff4f5741b"
      },
      "source": [
        "!git clone https://github.com/openai/gym.git\n",
        "%cd gym\n",
        "!pip install -e ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'gym' already exists and is not an empty directory.\n",
            "/content/gym\n",
            "Obtaining file:///content/gym\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym==0.18.0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym==0.18.0) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.18.0) (1.5.0)\n",
            "Requirement already satisfied: Pillow<=7.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.18.0) (7.0.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.18.0) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.18.0) (0.16.0)\n",
            "Installing collected packages: gym\n",
            "  Found existing installation: gym 0.18.0\n",
            "    Can't uninstall 'gym'. No files were found to uninstall.\n",
            "  Running setup.py develop for gym\n",
            "Successfully installed gym\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtC2hX1EcRXE"
      },
      "source": [
        "import gym\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import gnwrapper\n",
        "\n",
        "\n",
        "env = gnwrapper.Animation(gym.make('CartPole-v1'))\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# if gpu is to be used\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLwEcu9DcRXG"
      },
      "source": [
        "Replay Memory\n",
        "-------------\n",
        "\n",
        "We'll be using experience replay memory for training our DQN. It stores\n",
        "the transitions that the agent observes, allowing us to reuse this data\n",
        "later. By sampling from it randomly, the transitions that build up a\n",
        "batch are decorrelated. It has been shown that this greatly stabilizes\n",
        "and improves the DQN training procedure.\n",
        "\n",
        "For this, we're going to need two classses:\n",
        "\n",
        "-  ``Transition`` - a named tuple representing a single transition in\n",
        "   our environment. It essentially maps (state, action) pairs\n",
        "   to their (next_state, reward) result, with the state being the\n",
        "   screen difference image as described later on.\n",
        "-  ``ReplayMemory`` - a cyclic buffer of bounded size that holds the\n",
        "   transitions observed recently. It also implements a ``.sample()``\n",
        "   method for selecting a random batch of transitions for training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSeVgL-icRXI"
      },
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTVk3C1VC4q1"
      },
      "source": [
        "# memory"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UtYrPmQcRXK"
      },
      "source": [
        "Now, let's define our model. But first, let quickly recap what a DQN is.\n",
        "\n",
        "DQN algorithm\n",
        "-------------\n",
        "\n",
        "Our environment is deterministic, so all equations presented here are\n",
        "also formulated deterministically for the sake of simplicity. In the\n",
        "reinforcement learning literature, they would also contain expectations\n",
        "over stochastic transitions in the environment.\n",
        "\n",
        "Our aim will be to train a policy that tries to maximize the discounted,\n",
        "cumulative reward\n",
        "$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, where\n",
        "$R_{t_0}$ is also known as the *return*. The discount,\n",
        "$\\gamma$, should be a constant between $0$ and $1$\n",
        "that ensures the sum converges. It makes rewards from the uncertain far\n",
        "future less important for our agent than the ones in the near future\n",
        "that it can be fairly confident about.\n",
        "\n",
        "The main idea behind Q-learning is that if we had a function\n",
        "$Q^*: State \\times Action \\rightarrow \\mathbb{R}$, that could tell\n",
        "us what our return would be, if we were to take an action in a given\n",
        "state, then we could easily construct a policy that maximizes our\n",
        "rewards:\n",
        "\n",
        "\\begin{align}\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)\\end{align}\n",
        "\n",
        "However, we don't know everything about the world, so we don't have\n",
        "access to $Q^*$. But, since neural networks are universal function\n",
        "approximators, we can simply create one and train it to resemble\n",
        "$Q^*$.\n",
        "\n",
        "For our training update rule, we'll use a fact that every $Q$\n",
        "function for some policy obeys the Bellman equation:\n",
        "\n",
        "\\begin{align}Q^{\\pi}(s, a) = r + \\gamma Q^{\\pi}(s', \\pi(s'))\\end{align}\n",
        "\n",
        "The difference between the two sides of the equality is known as the\n",
        "temporal difference error, $\\delta$:\n",
        "\n",
        "\\begin{align}\\delta = Q(s, a) - (r + \\gamma \\max_a Q(s', a))\\end{align}\n",
        "\n",
        "To minimise this error, we will use the `Huber\n",
        "loss <https://en.wikipedia.org/wiki/Huber_loss>`__. The Huber loss acts\n",
        "like the mean squared error when the error is small, but like the mean\n",
        "absolute error when the error is large - this makes it more robust to\n",
        "outliers when the estimates of $Q$ are very noisy. We calculate\n",
        "this over a batch of transitions, $B$, sampled from the replay\n",
        "memory:\n",
        "\n",
        "\\begin{align}\\mathcal{L} = \\frac{1}{|B|}\\sum_{(s, a, s', r) \\ \\in \\ B} \\mathcal{L}(\\delta)\\end{align}\n",
        "\n",
        "\\begin{align}\\text{where} \\quad \\mathcal{L}(\\delta) = \\begin{cases}\n",
        "     \\frac{1}{2}{\\delta^2}  & \\text{for } |\\delta| \\le 1, \\\\\n",
        "     |\\delta| - \\frac{1}{2} & \\text{otherwise.}\n",
        "   \\end{cases}\\end{align}\n",
        "\n",
        "Q-network\n",
        "^^^^^^^^^\n",
        "\n",
        "Our model will be a convolutional neural network that takes in the\n",
        "difference between the current and previous screen patches. It has two\n",
        "outputs, representing $Q(s, \\mathrm{left})$ and\n",
        "$Q(s, \\mathrm{right})$ (where $s$ is the input to the\n",
        "network). In effect, the network is trying to predict the *expected return* of\n",
        "taking each action given the current input.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUOYgW9ycRXL"
      },
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, h, w, outputs):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Number of Linear input connections depends on output of conv2d layers\n",
        "        # and therefore the input image size, so compute it.\n",
        "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
        "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
        "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
        "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
        "        linear_input_size = convw * convh * 32\n",
        "        self.head = nn.Linear(linear_input_size, outputs)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        return self.head(x.view(x.size(0), -1))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySdqfHsxcRXN"
      },
      "source": [
        "Input extraction\n",
        "^^^^^^^^^^^^^^^^\n",
        "\n",
        "The code below are utilities for extracting and processing rendered\n",
        "images from the environment. It uses the ``torchvision`` package, which\n",
        "makes it easy to compose image transforms. Once you run the cell it will\n",
        "display an example patch that it extracted.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZq4VjDqVrms"
      },
      "source": [
        "## CaR REWREC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRplH8vdVpw0"
      },
      "source": [
        "import sys, math\n",
        "import numpy as np\n",
        "\n",
        "import Box2D\n",
        "from Box2D.b2 import (edgeShape, circleShape, fixtureDef, polygonShape, revoluteJointDef, contactListener)\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "from gym.envs.box2d.car_dynamics import Car\n",
        "from gym.utils import colorize, seeding, EzPickle\n",
        "\n",
        "import pyglet\n",
        "from pyglet import gl\n",
        "\n",
        "# Easiest continuous control task to learn from pixels, a top-down racing environment.\n",
        "# Discrete control is reasonable in this environment as well, on/off discretization is\n",
        "# fine.\n",
        "#\n",
        "# State consists of STATE_W x STATE_H pixels.\n",
        "#\n",
        "# Reward is -0.1 every frame and +1000/N for every track tile visited, where N is\n",
        "# the total number of tiles visited in the track. For example, if you have finished in 732 frames,\n",
        "# your reward is 1000 - 0.1*732 = 926.8 points.\n",
        "#\n",
        "# Game is solved when agent consistently gets 900+ points. Track generated is random every episode.\n",
        "#\n",
        "# Episode finishes when all tiles are visited. Car also can go outside of PLAYFIELD, that\n",
        "# is far off the track, then it will get -100 and die.\n",
        "#\n",
        "# Some indicators shown at the bottom of the window and the state RGB buffer. From\n",
        "# left to right: true speed, four ABS sensors, steering wheel position and gyroscope.\n",
        "#\n",
        "# To play yourself (it's rather fast for humans), type:\n",
        "#\n",
        "# python gym/envs/box2d/car_racing.py\n",
        "#\n",
        "# Remember it's powerful rear-wheel drive car, don't press accelerator and turn at the\n",
        "# same time.\n",
        "#\n",
        "# Created by Oleg Klimov. Licensed on the same terms as the rest of OpenAI Gym.\n",
        "\n",
        "STATE_W = 96   # less than Atari 160x192\n",
        "STATE_H = 96\n",
        "VIDEO_W = 600\n",
        "VIDEO_H = 400\n",
        "WINDOW_W = 1000\n",
        "WINDOW_H = 800\n",
        "\n",
        "SCALE       = 6.0        # Track scale\n",
        "TRACK_RAD   = 900/SCALE  # Track is heavily morphed circle with this radius\n",
        "PLAYFIELD   = 2000/SCALE # Game over boundary\n",
        "FPS         = 50         # Frames per second\n",
        "ZOOM        = 2.7        # Camera zoom\n",
        "ZOOM_FOLLOW = True       # Set to False for fixed view (don't use zoom)\n",
        "\n",
        "\n",
        "TRACK_DETAIL_STEP = 21/SCALE\n",
        "TRACK_TURN_RATE = 0.31\n",
        "TRACK_WIDTH = 40/SCALE\n",
        "BORDER = 8/SCALE\n",
        "BORDER_MIN_COUNT = 4\n",
        "\n",
        "ROAD_COLOR = [0.4, 0.4, 0.4]\n",
        "\n",
        "class FrictionDetector(contactListener):\n",
        "    def __init__(self, env):\n",
        "        contactListener.__init__(self)\n",
        "        self.env = env\n",
        "    def BeginContact(self, contact):\n",
        "        self._contact(contact, True)\n",
        "    def EndContact(self, contact):\n",
        "        self._contact(contact, False)\n",
        "    def _contact(self, contact, begin):\n",
        "        tile = None\n",
        "        obj = None\n",
        "        u1 = contact.fixtureA.body.userData\n",
        "        u2 = contact.fixtureB.body.userData\n",
        "        if u1 and \"road_friction\" in u1.__dict__:\n",
        "            tile = u1\n",
        "            obj  = u2\n",
        "        if u2 and \"road_friction\" in u2.__dict__:\n",
        "            tile = u2\n",
        "            obj  = u1\n",
        "        if not tile:\n",
        "            return\n",
        "\n",
        "        tile.color[0] = ROAD_COLOR[0]\n",
        "        tile.color[1] = ROAD_COLOR[1]\n",
        "        tile.color[2] = ROAD_COLOR[2]\n",
        "        if not obj or \"tiles\" not in obj.__dict__:\n",
        "            return\n",
        "        if begin:\n",
        "            obj.tiles.add(tile)\n",
        "            # print tile.road_friction, \"ADD\", len(obj.tiles)\n",
        "            if not tile.road_visited:\n",
        "                tile.road_visited = True\n",
        "                self.env.reward += 1000.0/len(self.env.track)\n",
        "                self.env.tile_visited_count += 1\n",
        "        else:\n",
        "            obj.tiles.remove(tile)\n",
        "            # print tile.road_friction, \"DEL\", len(obj.tiles) -- should delete to zero when on grass (this works)\n",
        "\n",
        "class CarRacing(gym.Env, EzPickle):\n",
        "    metadata = {\n",
        "        'render.modes': ['human', 'rgb_array', 'state_pixels'],\n",
        "        'video.frames_per_second' : FPS\n",
        "    }\n",
        "\n",
        "    def __init__(self, verbose=1):\n",
        "        EzPickle.__init__(self)\n",
        "        self.seed()\n",
        "        self.contactListener_keepref = FrictionDetector(self)\n",
        "        self.world = Box2D.b2World((0,0), contactListener=self.contactListener_keepref)\n",
        "        self.viewer = None\n",
        "        self.invisible_state_window = None\n",
        "        self.invisible_video_window = None\n",
        "        self.road = None\n",
        "        self.car = None\n",
        "        self.reward = 0.0\n",
        "        self.prev_reward = 0.0\n",
        "        self.verbose = verbose\n",
        "        self.fd_tile = fixtureDef(\n",
        "                shape = polygonShape(vertices=\n",
        "                    [(0, 0),(1, 0),(1, -1),(0, -1)]))\n",
        "\n",
        "        self.action_space = spaces.Box( np.array([-1,0,0]), np.array([+1,+1,+1]), dtype=np.float32)  # steer, gas, brake\n",
        "        self.actions = [np.array([-1,0,0], dtype=np.float32), \n",
        "                        np.array([1,0,0], dtype=np.float32), \n",
        "                        np.array([0,1,0], dtype=np.float32), \n",
        "                        np.array([0,0,0.8], dtype=np.float32), \n",
        "                        np.array([0,0,0], dtype=np.float32)]  # left right, gas, brake, nothing\n",
        "\n",
        "        self.observation_space = spaces.Box(low=0, high=255, shape=(STATE_H, STATE_W, 3), dtype=np.uint8)\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def _destroy(self):\n",
        "        if not self.road:\n",
        "            return\n",
        "        for t in self.road:\n",
        "            self.world.DestroyBody(t)\n",
        "        self.road = []\n",
        "        self.car.destroy()\n",
        "\n",
        "    def _create_track(self):\n",
        "        CHECKPOINTS = 12\n",
        "\n",
        "        # Create checkpoints\n",
        "        checkpoints = []\n",
        "        for c in range(CHECKPOINTS):\n",
        "            alpha = 2*math.pi*c/CHECKPOINTS + self.np_random.uniform(0, 2*math.pi*1/CHECKPOINTS)\n",
        "            rad = self.np_random.uniform(TRACK_RAD/3, TRACK_RAD)\n",
        "            if c==0:\n",
        "                alpha = 0\n",
        "                rad = 1.5*TRACK_RAD\n",
        "            if c==CHECKPOINTS-1:\n",
        "                alpha = 2*math.pi*c/CHECKPOINTS\n",
        "                self.start_alpha = 2*math.pi*(-0.5)/CHECKPOINTS\n",
        "                rad = 1.5*TRACK_RAD\n",
        "            checkpoints.append( (alpha, rad*math.cos(alpha), rad*math.sin(alpha)) )\n",
        "\n",
        "        # print \"\\n\".join(str(h) for h in checkpoints)\n",
        "        # self.road_poly = [ (    # uncomment this to see checkpoints\n",
        "        #    [ (tx,ty) for a,tx,ty in checkpoints ],\n",
        "        #    (0.7,0.7,0.9) ) ]\n",
        "        self.road = []\n",
        "\n",
        "        # Go from one checkpoint to another to create track\n",
        "        x, y, beta = 1.5*TRACK_RAD, 0, 0\n",
        "        dest_i = 0\n",
        "        laps = 0\n",
        "        track = []\n",
        "        no_freeze = 2500\n",
        "        visited_other_side = False\n",
        "        while True:\n",
        "            alpha = math.atan2(y, x)\n",
        "            if visited_other_side and alpha > 0:\n",
        "                laps += 1\n",
        "                visited_other_side = False\n",
        "            if alpha < 0:\n",
        "                visited_other_side = True\n",
        "                alpha += 2*math.pi\n",
        "            while True: # Find destination from checkpoints\n",
        "                failed = True\n",
        "                while True:\n",
        "                    dest_alpha, dest_x, dest_y = checkpoints[dest_i % len(checkpoints)]\n",
        "                    if alpha <= dest_alpha:\n",
        "                        failed = False\n",
        "                        break\n",
        "                    dest_i += 1\n",
        "                    if dest_i % len(checkpoints) == 0:\n",
        "                        break\n",
        "                if not failed:\n",
        "                    break\n",
        "                alpha -= 2*math.pi\n",
        "                continue\n",
        "            r1x = math.cos(beta)\n",
        "            r1y = math.sin(beta)\n",
        "            p1x = -r1y\n",
        "            p1y = r1x\n",
        "            dest_dx = dest_x - x  # vector towards destination\n",
        "            dest_dy = dest_y - y\n",
        "            proj = r1x*dest_dx + r1y*dest_dy  # destination vector projected on rad\n",
        "            while beta - alpha >  1.5*math.pi:\n",
        "                 beta -= 2*math.pi\n",
        "            while beta - alpha < -1.5*math.pi:\n",
        "                 beta += 2*math.pi\n",
        "            prev_beta = beta\n",
        "            proj *= SCALE\n",
        "            if proj >  0.3:\n",
        "                 beta -= min(TRACK_TURN_RATE, abs(0.001*proj))\n",
        "            if proj < -0.3:\n",
        "                 beta += min(TRACK_TURN_RATE, abs(0.001*proj))\n",
        "            x += p1x*TRACK_DETAIL_STEP\n",
        "            y += p1y*TRACK_DETAIL_STEP\n",
        "            track.append( (alpha,prev_beta*0.5 + beta*0.5,x,y) )\n",
        "            if laps > 4:\n",
        "                 break\n",
        "            no_freeze -= 1\n",
        "            if no_freeze==0:\n",
        "                 break\n",
        "        # print \"\\n\".join([str(t) for t in enumerate(track)])\n",
        "\n",
        "        # Find closed loop range i1..i2, first loop should be ignored, second is OK\n",
        "        i1, i2 = -1, -1\n",
        "        i = len(track)\n",
        "        while True:\n",
        "            i -= 1\n",
        "            if i==0:\n",
        "                return False  # Failed\n",
        "            pass_through_start = track[i][0] > self.start_alpha and track[i-1][0] <= self.start_alpha\n",
        "            if pass_through_start and i2==-1:\n",
        "                i2 = i\n",
        "            elif pass_through_start and i1==-1:\n",
        "                i1 = i\n",
        "                break\n",
        "        if self.verbose == 1:\n",
        "            print(\"Track generation: %i..%i -> %i-tiles track\" % (i1, i2, i2-i1))\n",
        "        assert i1!=-1\n",
        "        assert i2!=-1\n",
        "\n",
        "        track = track[i1:i2-1]\n",
        "\n",
        "        first_beta = track[0][1]\n",
        "        first_perp_x = math.cos(first_beta)\n",
        "        first_perp_y = math.sin(first_beta)\n",
        "        # Length of perpendicular jump to put together head and tail\n",
        "        well_glued_together = np.sqrt(\n",
        "            np.square( first_perp_x*(track[0][2] - track[-1][2]) ) +\n",
        "            np.square( first_perp_y*(track[0][3] - track[-1][3]) ))\n",
        "        if well_glued_together > TRACK_DETAIL_STEP:\n",
        "            return False\n",
        "\n",
        "        # Red-white border on hard turns\n",
        "        border = [False]*len(track)\n",
        "        for i in range(len(track)):\n",
        "            good = True\n",
        "            oneside = 0\n",
        "            for neg in range(BORDER_MIN_COUNT):\n",
        "                beta1 = track[i-neg-0][1]\n",
        "                beta2 = track[i-neg-1][1]\n",
        "                good &= abs(beta1 - beta2) > TRACK_TURN_RATE*0.2\n",
        "                oneside += np.sign(beta1 - beta2)\n",
        "            good &= abs(oneside) == BORDER_MIN_COUNT\n",
        "            border[i] = good\n",
        "        for i in range(len(track)):\n",
        "            for neg in range(BORDER_MIN_COUNT):\n",
        "                border[i-neg] |= border[i]\n",
        "\n",
        "        # Create tiles\n",
        "        for i in range(len(track)):\n",
        "            alpha1, beta1, x1, y1 = track[i]\n",
        "            alpha2, beta2, x2, y2 = track[i-1]\n",
        "            road1_l = (x1 - TRACK_WIDTH*math.cos(beta1), y1 - TRACK_WIDTH*math.sin(beta1))\n",
        "            road1_r = (x1 + TRACK_WIDTH*math.cos(beta1), y1 + TRACK_WIDTH*math.sin(beta1))\n",
        "            road2_l = (x2 - TRACK_WIDTH*math.cos(beta2), y2 - TRACK_WIDTH*math.sin(beta2))\n",
        "            road2_r = (x2 + TRACK_WIDTH*math.cos(beta2), y2 + TRACK_WIDTH*math.sin(beta2))\n",
        "            vertices = [road1_l, road1_r, road2_r, road2_l]\n",
        "            self.fd_tile.shape.vertices = vertices\n",
        "            t = self.world.CreateStaticBody(fixtures=self.fd_tile)\n",
        "            t.userData = t\n",
        "            c = 0.01*(i%3)\n",
        "            t.color = [ROAD_COLOR[0] + c, ROAD_COLOR[1] + c, ROAD_COLOR[2] + c]\n",
        "            t.road_visited = False\n",
        "            t.road_friction = 1.0\n",
        "            t.fixtures[0].sensor = True\n",
        "            self.road_poly.append(( [road1_l, road1_r, road2_r, road2_l], t.color ))\n",
        "            self.road.append(t)\n",
        "            if border[i]:\n",
        "                side = np.sign(beta2 - beta1)\n",
        "                b1_l = (x1 + side* TRACK_WIDTH        *math.cos(beta1), y1 + side* TRACK_WIDTH        *math.sin(beta1))\n",
        "                b1_r = (x1 + side*(TRACK_WIDTH+BORDER)*math.cos(beta1), y1 + side*(TRACK_WIDTH+BORDER)*math.sin(beta1))\n",
        "                b2_l = (x2 + side* TRACK_WIDTH        *math.cos(beta2), y2 + side* TRACK_WIDTH        *math.sin(beta2))\n",
        "                b2_r = (x2 + side*(TRACK_WIDTH+BORDER)*math.cos(beta2), y2 + side*(TRACK_WIDTH+BORDER)*math.sin(beta2))\n",
        "                self.road_poly.append(( [b1_l, b1_r, b2_r, b2_l], (1,1,1) if i%2==0 else (1,0,0) ))\n",
        "        self.track = track\n",
        "        return True\n",
        "\n",
        "    def reset(self):\n",
        "        self._destroy()\n",
        "        self.reward = 0.0\n",
        "        self.prev_reward = 0.0\n",
        "        self.tile_visited_count = 0\n",
        "        self.t = 0.0\n",
        "        self.road_poly = []\n",
        "\n",
        "        while True:\n",
        "            success = self._create_track()\n",
        "            if success:\n",
        "                break\n",
        "            if self.verbose == 1:\n",
        "                print(\"retry to generate track (normal if there are not many of this messages)\")\n",
        "        self.car = Car(self.world, *self.track[0][1:4])\n",
        "\n",
        "        return self.step(None)[0]\n",
        "\n",
        "    def step(self, action):\n",
        "        if action is not None:\n",
        "            self.car.steer(-action[0])\n",
        "            self.car.gas(action[1])\n",
        "            self.car.brake(action[2])\n",
        "\n",
        "        self.car.step(1.0/FPS)\n",
        "        self.world.Step(1.0/FPS, 6*30, 2*30)\n",
        "        self.t += 1.0/FPS\n",
        "\n",
        "        self.state = self.render(\"state_pixels\")\n",
        "\n",
        "        step_reward = 0\n",
        "        done = False\n",
        "        if action is not None: # First step without action, called from reset()\n",
        "            self.reward -= 0.1\n",
        "            # We actually don't want to count fuel spent, we want car to be faster.\n",
        "            # self.reward -=  10 * self.car.fuel_spent / ENGINE_POWER\n",
        "            self.car.fuel_spent = 0.0\n",
        "            step_reward = self.reward - self.prev_reward\n",
        "            self.prev_reward = self.reward\n",
        "            if self.tile_visited_count==len(self.track):\n",
        "                done = True\n",
        "            x, y = self.car.hull.position\n",
        "            if abs(x) > PLAYFIELD or abs(y) > PLAYFIELD:\n",
        "                done = True\n",
        "                step_reward = -100\n",
        "\n",
        "        return self.state, step_reward, done, {}\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        assert mode in ['human', 'state_pixels', 'rgb_array']\n",
        "        if self.viewer is None:\n",
        "            from gym.envs.classic_control import rendering\n",
        "            self.viewer = rendering.Viewer(WINDOW_W, WINDOW_H)\n",
        "            self.score_label = pyglet.text.Label('0000', font_size=36,\n",
        "                x=20, y=WINDOW_H*2.5/40.00, anchor_x='left', anchor_y='center',\n",
        "                color=(255,255,255,255))\n",
        "            self.transform = rendering.Transform()\n",
        "\n",
        "        if \"t\" not in self.__dict__: return  # reset() not called yet\n",
        "\n",
        "        zoom = 0.1*SCALE*max(1-self.t, 0) + ZOOM*SCALE*min(self.t, 1)   # Animate zoom first second\n",
        "        zoom = 0.1*SCALE*0 + ZOOM*SCALE*1   # Animate zoom first second\n",
        "        zoom_state  = ZOOM*SCALE*STATE_W/WINDOW_W\n",
        "        zoom_video  = ZOOM*SCALE*VIDEO_W/WINDOW_W\n",
        "        scroll_x = self.car.hull.position[0]\n",
        "        scroll_y = self.car.hull.position[1]\n",
        "        angle = -self.car.hull.angle\n",
        "        vel = self.car.hull.linearVelocity\n",
        "        if np.linalg.norm(vel) > 0.5:\n",
        "            angle = math.atan2(vel[0], vel[1])\n",
        "        self.transform.set_scale(zoom, zoom)\n",
        "        self.transform.set_translation(\n",
        "            WINDOW_W/2 - (scroll_x*zoom*math.cos(angle) - scroll_y*zoom*math.sin(angle)),\n",
        "            WINDOW_H/4 - (scroll_x*zoom*math.sin(angle) + scroll_y*zoom*math.cos(angle)) )\n",
        "        self.transform.set_rotation(angle)\n",
        "\n",
        "        self.car.draw(self.viewer, mode!=\"state_pixels\")\n",
        "\n",
        "        arr = None\n",
        "        win = self.viewer.window\n",
        "        win.switch_to()\n",
        "        win.dispatch_events()\n",
        "\n",
        "        win.clear()\n",
        "        t = self.transform\n",
        "        if mode=='rgb_array':\n",
        "            VP_W = VIDEO_W\n",
        "            VP_H = VIDEO_H\n",
        "        elif mode == 'state_pixels':\n",
        "            VP_W = STATE_W\n",
        "            VP_H = STATE_H\n",
        "        else:\n",
        "            pixel_scale = 1\n",
        "            if hasattr(win.context, '_nscontext'):\n",
        "                pixel_scale = win.context._nscontext.view().backingScaleFactor()  # pylint: disable=protected-access\n",
        "            VP_W = int(pixel_scale * WINDOW_W)\n",
        "            VP_H = int(pixel_scale * WINDOW_H)\n",
        "\n",
        "        gl.glViewport(0, 0, VP_W, VP_H)\n",
        "        t.enable()\n",
        "        self.render_road()\n",
        "        for geom in self.viewer.onetime_geoms:\n",
        "            geom.render()\n",
        "        self.viewer.onetime_geoms = []\n",
        "        t.disable()\n",
        "        self.render_indicators(WINDOW_W, WINDOW_H)\n",
        "\n",
        "        if mode == 'human':\n",
        "            win.flip()\n",
        "            return self.viewer.isopen\n",
        "\n",
        "        image_data = pyglet.image.get_buffer_manager().get_color_buffer().get_image_data()\n",
        "        arr = np.fromstring(image_data.get_data(), dtype=np.uint8, sep='')\n",
        "        arr = arr.reshape(VP_H, VP_W, 4)\n",
        "        arr = arr[::-1, :, 0:3]\n",
        "\n",
        "        return arr\n",
        "\n",
        "    def close(self):\n",
        "        if self.viewer is not None:\n",
        "            self.viewer.close()\n",
        "            self.viewer = None\n",
        "\n",
        "    def render_road(self):\n",
        "        gl.glBegin(gl.GL_QUADS)\n",
        "        gl.glColor4f(0.4, 0.8, 0.4, 1.0)\n",
        "        gl.glVertex3f(-PLAYFIELD, +PLAYFIELD, 0)\n",
        "        gl.glVertex3f(+PLAYFIELD, +PLAYFIELD, 0)\n",
        "        gl.glVertex3f(+PLAYFIELD, -PLAYFIELD, 0)\n",
        "        gl.glVertex3f(-PLAYFIELD, -PLAYFIELD, 0)\n",
        "        gl.glColor4f(0.4, 0.9, 0.4, 1.0)\n",
        "        k = PLAYFIELD/20.0\n",
        "        for x in range(-20, 20, 2):\n",
        "            for y in range(-20, 20, 2):\n",
        "                gl.glVertex3f(k*x + k, k*y + 0, 0)\n",
        "                gl.glVertex3f(k*x + 0, k*y + 0, 0)\n",
        "                gl.glVertex3f(k*x + 0, k*y + k, 0)\n",
        "                gl.glVertex3f(k*x + k, k*y + k, 0)\n",
        "        for poly, color in self.road_poly:\n",
        "            gl.glColor4f(color[0], color[1], color[2], 1)\n",
        "            for p in poly:\n",
        "                gl.glVertex3f(p[0], p[1], 0)\n",
        "        gl.glEnd()\n",
        "\n",
        "    def render_indicators(self, W, H):\n",
        "        gl.glBegin(gl.GL_QUADS)\n",
        "        s = W/40.0\n",
        "        h = H/40.0\n",
        "        gl.glColor4f(0,0,0,1)\n",
        "        gl.glVertex3f(W, 0, 0)\n",
        "        gl.glVertex3f(W, 5*h, 0)\n",
        "        gl.glVertex3f(0, 5*h, 0)\n",
        "        gl.glVertex3f(0, 0, 0)\n",
        "        def vertical_ind(place, val, color):\n",
        "            gl.glColor4f(color[0], color[1], color[2], 1)\n",
        "            gl.glVertex3f((place+0)*s, h + h*val, 0)\n",
        "            gl.glVertex3f((place+1)*s, h + h*val, 0)\n",
        "            gl.glVertex3f((place+1)*s, h, 0)\n",
        "            gl.glVertex3f((place+0)*s, h, 0)\n",
        "        def horiz_ind(place, val, color):\n",
        "            gl.glColor4f(color[0], color[1], color[2], 1)\n",
        "            gl.glVertex3f((place+0)*s, 4*h , 0)\n",
        "            gl.glVertex3f((place+val)*s, 4*h, 0)\n",
        "            gl.glVertex3f((place+val)*s, 2*h, 0)\n",
        "            gl.glVertex3f((place+0)*s, 2*h, 0)\n",
        "        true_speed = np.sqrt(np.square(self.car.hull.linearVelocity[0]) + np.square(self.car.hull.linearVelocity[1]))\n",
        "        vertical_ind(5, 0.02*true_speed, (1,1,1))\n",
        "        vertical_ind(7, 0.01*self.car.wheels[0].omega, (0.0,0,1)) # ABS sensors\n",
        "        vertical_ind(8, 0.01*self.car.wheels[1].omega, (0.0,0,1))\n",
        "        vertical_ind(9, 0.01*self.car.wheels[2].omega, (0.2,0,1))\n",
        "        vertical_ind(10,0.01*self.car.wheels[3].omega, (0.2,0,1))\n",
        "        horiz_ind(20, -10.0*self.car.wheels[0].joint.angle, (0,1,0))\n",
        "        horiz_ind(30, -0.8*self.car.hull.angularVelocity, (1,0,0))\n",
        "        gl.glEnd()\n",
        "        self.score_label.text = \"%04i\" % self.reward\n",
        "        self.score_label.draw()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c61fq6FMVv0A"
      },
      "source": [
        "## TEST CAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "-3RPjFbySdb6",
        "outputId": "2dcd5d36-3ade-41b9-86a1-5da49c5b2279"
      },
      "source": [
        "# from gym.envs.box2d import CarRacing\n",
        "env = gnwrapper.Animation(CarRacing())\n",
        "env = CarRacing()\n",
        "\n",
        "env.reset()\n",
        "env.render()\n",
        "im = env.render(\"state_pixels\")\n",
        "\n",
        "def state_image_preprocess(state_image):\n",
        "    # crop image\n",
        "    state_image = state_image[0:84, :, :]\n",
        "    state_image = state_image.transpose((2,0,1))\n",
        "    # to torch\n",
        "    state_image = np.ascontiguousarray(state_image, dtype=np.float32) / 255\n",
        "    state_image = torch.from_numpy(state_image)\n",
        "    return state_image.unsqueeze(0).to(device)\n",
        "\n",
        "# plt.imshow(im)\n",
        "state_image_preprocess(im).shape\n",
        "plt.imshow(state_image_preprocess(im).cpu().squeeze(0).permute(1, 2, 0).numpy())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Track generation: 1160..1454 -> 294-tiles track\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:413: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe881d676d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVLHsrOIcRXO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "754d64bc-3b0b-406e-a4ca-b336bd2ebade"
      },
      "source": [
        "resize = T.Compose([T.ToPILImage(),\n",
        "                    T.Resize(40, interpolation=Image.CUBIC),\n",
        "                    T.ToTensor()])\n",
        "\n",
        "\n",
        "def get_cart_location(screen_width):\n",
        "    world_width = env.x_threshold * 2\n",
        "    scale = screen_width / world_width\n",
        "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
        "\n",
        "# def get_screen():\n",
        "#     # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
        "#     # such as 800x1200x3. Transpose it into torch order (CHW).\n",
        "#     state_image = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
        "#     state_image = state_image[0:84, :, :]\n",
        "#     state_image = state_image.transpose((2,0,1))\n",
        "#     # to torch\n",
        "#     state_image = np.ascontiguousarray(state_image, dtype=np.float32) / 255\n",
        "#     state_image = torch.from_numpy(state_image)\n",
        "#     return resize(state_image).unsqueeze(0).to(device)\n",
        "#     # Cart is in the lower half, so strip off the top and bottom of the screen\n",
        "#     _, screen_height, screen_width = screen.shape\n",
        "#     screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
        "#     view_width = int(screen_width * 0.6)\n",
        "#     cart_location = get_cart_location(screen_width)\n",
        "#     if cart_location < view_width // 2:\n",
        "#         slice_range = slice(view_width)\n",
        "#     elif cart_location > (screen_width - view_width // 2):\n",
        "#         slice_range = slice(-view_width, None)\n",
        "#     else:\n",
        "#         slice_range = slice(cart_location - view_width // 2,\n",
        "#                             cart_location + view_width // 2)\n",
        "#     # Strip off the edges, so that we have a square image centered on a cart\n",
        "#     screen = screen[:, :, slice_range]\n",
        "#     # Convert to float, rescale, convert to torch tensor\n",
        "#     # (this doesn't require a copy)\n",
        "#     screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
        "#     screen = torch.from_numpy(screen)\n",
        "#     # Resize, and add a batch dimension (BCHW)\n",
        "#     return resize(screen).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "def get_screen():\n",
        "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
        "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
        "    state_image = env.render(mode='state_pixels')\n",
        "    state_image = state_image[0:84, :, :]\n",
        "    state_image = state_image.transpose((2,0,1))\n",
        "    # to torch\n",
        "    state_image = np.ascontiguousarray(state_image, dtype=np.float32) / 255\n",
        "    state_image = torch.from_numpy(state_image)\n",
        "    return state_image.unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
        "    _, screen_height, screen_width = screen.shape\n",
        "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
        "    view_width = int(screen_width * 0.6)\n",
        "    cart_location = get_cart_location(screen_width)\n",
        "    if cart_location < view_width // 2:\n",
        "        slice_range = slice(view_width)\n",
        "    elif cart_location > (screen_width - view_width // 2):\n",
        "        slice_range = slice(-view_width, None)\n",
        "    else:\n",
        "        slice_range = slice(cart_location - view_width // 2,\n",
        "                            cart_location + view_width // 2)\n",
        "    # Strip off the edges, so that we have a square image centered on a cart\n",
        "    screen = screen[:, :, slice_range]\n",
        "    # Convert to float, rescale, convert to torch tensor\n",
        "    # (this doesn't require a copy)\n",
        "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
        "    screen = torch.from_numpy(screen)\n",
        "    # Resize, and add a batch dimension (BCHW)\n",
        "    return resize(screen).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "env.reset()\n",
        "plt.figure()\n",
        "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy())\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Track generation: 1170..1465 -> 295-tiles track\n",
            "retry to generate track (normal if there are not many of this messages)\n",
            "Track generation: 1227..1538 -> 311-tiles track\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:413: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES2-Xj9PcRXQ"
      },
      "source": [
        "Training\n",
        "--------\n",
        "\n",
        "Hyperparameters and utilities\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "This cell instantiates our model and its optimizer, and defines some\n",
        "utilities:\n",
        "\n",
        "-  ``select_action`` - will select an action accordingly to an epsilon\n",
        "   greedy policy. Simply put, we'll sometimes use our model for choosing\n",
        "   the action, and sometimes we'll just sample one uniformly. The\n",
        "   probability of choosing a random action will start at ``EPS_START``\n",
        "   and will decay exponentially towards ``EPS_END``. ``EPS_DECAY``\n",
        "   controls the rate of the decay.\n",
        "-  ``plot_durations`` - a helper for plotting the durations of episodes,\n",
        "   along with an average over the last 100 episodes (the measure used in\n",
        "   the official evaluations). The plot will be underneath the cell\n",
        "   containing the main training loop, and will update after every\n",
        "   episode.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf1pNJBocotM",
        "outputId": "08d5cdb8-d681-4853-aebe-da3f60af717d"
      },
      "source": [
        "env.actions"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-1.,  0.,  0.], dtype=float32),\n",
              " array([1., 0., 0.], dtype=float32),\n",
              " array([0., 1., 0.], dtype=float32),\n",
              " array([0. , 0. , 0.8], dtype=float32),\n",
              " array([0., 0., 0.], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2U5U_IKcRXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d82b99-6e8c-40dc-f0cc-241404eb3c4a"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.999\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 200\n",
        "TARGET_UPDATE = 10\n",
        "\n",
        "# Get screen size so that we can initialize layers correctly based on shape\n",
        "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
        "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
        "init_screen = get_screen()\n",
        "_, _, screen_height, screen_width = init_screen.shape\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "# n_actions = env.action_space.n\n",
        "n_actions = len(env.actions)\n",
        "\n",
        "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
        "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.RMSprop(policy_net.parameters())\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            # t.max(1) will return largest column value of each row.\n",
        "            # second column on max result is index of where max element was\n",
        "            # found, so we pick action with the larger expected reward.\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:413: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPxVE3_w276K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15bfb1d2-aefd-4078-e344-f8063f7b4f28"
      },
      "source": [
        "memory.position"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QGYM9yBcRXT"
      },
      "source": [
        "Training loop\n",
        "^^^^^^^^^^^^^\n",
        "\n",
        "Finally, the code for training our model.\n",
        "\n",
        "Here, you can find an ``optimize_model`` function that performs a\n",
        "single step of the optimization. It first samples a batch, concatenates\n",
        "all the tensors into a single one, computes $Q(s_t, a_t)$ and\n",
        "$V(s_{t+1}) = \\max_a Q(s_{t+1}, a)$, and combines them into our\n",
        "loss. By defition we set $V(s) = 0$ if $s$ is a terminal\n",
        "state. We also use a target network to compute $V(s_{t+1})$ for\n",
        "added stability. The target network has its weights kept frozen most of\n",
        "the time, but is updated with the policy network's weights every so often.\n",
        "This is usually a set number of steps but we shall use episodes for\n",
        "simplicity.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaxGRO2ScRXU"
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    debug=False\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
        "\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "\n",
        "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "    \n",
        "    if debug:\n",
        "        print(\"action_batch\", action_batch.size())\n",
        "        print(\"reward_batch\", reward_batch.size())\n",
        "        print(\"state_batch\", state_batch.size())\n",
        "        print(\"state_action_values\", state_action_values.size())\n",
        "        print(\"non_final_next_states\", non_final_next_states.size())\n",
        "        print(\"expected_state_action_values\", expected_state_action_values.size())\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8BQ4jUiI3y2"
      },
      "source": [
        "optimize_model()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU17NcQmcRXV"
      },
      "source": [
        "Below, you can find the main training loop. At the beginning we reset\n",
        "the environment and initialize the ``state`` Tensor. Then, we sample\n",
        "an action, execute it, observe the next screen and the reward (always\n",
        "1), and optimize our model once. When the episode ends (our model\n",
        "fails), we restart the loop.\n",
        "\n",
        "Below, `num_episodes` is set small. You should download\n",
        "the notebook and run lot more epsiodes, such as 300+ for meaningful\n",
        "duration improvements.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7DH_e8hcRXV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "468867151d0449d083616ee2d3c21978",
            "5e1d263a4f1d49e1a6148823d3d16dfa",
            "2b282dee54624867b827d59152a853f7",
            "674b5dd08fff481d88688cbf715441a0",
            "e658c75b9d6c4598a45ea69b7a9e52b8",
            "7ab710871abd4fbb9d228a311d0ee390",
            "b7215d63d69a4f3b8bc1c43c31ae7397",
            "3cf2a659e1ca4883a20b82f1a7f9daeb"
          ]
        },
        "outputId": "42023536-60b5-4ebd-9b28-de0f3cf14d88"
      },
      "source": [
        "\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(30)\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import os\n",
        "import cv2\n",
        "import base64\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from collections import deque\n",
        "from datetime import datetime\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "# import wandb\n",
        "import wandb\n",
        "import time\n",
        "\n",
        "# record gameplay video\n",
        "# display = Display(visible=0, size=(1400, 900))\n",
        "# display.start()\n",
        "\n",
        "DEBUG               = False\n",
        "NUM_OF_EPISODES     = 5\n",
        "NUM_OF_STEPS        = 100\n",
        "LOG_VIDEO_EPISODES  = 2\n",
        "WANDB_ID            = \"sexyid123_new2\"\n",
        "WNDB_NAME           = \"Test_bruuuu_new_new2\"\n",
        "LOAD_SAVED_MODEL    = False\n",
        "MODEL_SAVE_NAME     = \"DQN_test_model\"\n",
        "OPTIMIZER_SAVE_NAME = \"DQN_test_optimizer\"\n",
        "SAVED_MODEL_VERSION = \"latest\"\n",
        "\n",
        "\n",
        "# wnadb api key\n",
        "# 00d5bfbd342bb73d5aaf4f2833436d20457ef040\n",
        "os.environ[\"WANDB_ENTITY\"]  = \"andreas_giannoutsos\"\n",
        "os.environ[\"WANDB_PROJECT\"] = \"gym_car_racer\"\n",
        "os.environ[\"WANDB_RESUME\"]  = \"allow\"\n",
        "wandb.init(resume=WANDB_ID)\n",
        "wandb.run.name = WNDB_NAME\n",
        "\n",
        "# load model\n",
        "if LOAD_SAVED_MODEL:\n",
        "    try:\n",
        "        model_artifact = wandb.use_artifact(MODEL_SAVE_NAME+':'+SAVED_MODEL_VERSION, type='model')\n",
        "        artifact_dir = model_artifact.download()\n",
        "        saved_model = torch.load(artifact_dir+\"/\"+MODEL_SAVE_NAME+\".pth\")\n",
        "        saved_optimizer = torch.load(artifact_dir+\"/\"+OPTIMIZER_SAVE_NAME+\".pth\")\n",
        "    except:\n",
        "        print(\"no model found\")\n",
        "\n",
        "env = CarRacing()\n",
        "\n",
        "for i_episode in range(NUM_OF_EPISODES):\n",
        "\n",
        "    # Initialize the environment and state    \n",
        "    if (i_episode % LOG_VIDEO_EPISODES == 0):\n",
        "        env = gym.wrappers.Monitor(CarRacing(), './video', force=True)\n",
        "    else:\n",
        "        env = CarRacing()\n",
        "        \n",
        "    env.reset()\n",
        "    last_screen = get_screen()\n",
        "    current_screen = get_screen()\n",
        "    state = current_screen - last_screen\n",
        "    for t in range(NUM_OF_STEPS):\n",
        "\n",
        "        ################# Select and perform an action ##################\n",
        "        fw_start = time.time() \n",
        "        action = select_action(state)\n",
        "        fw_end = time.time() \n",
        "        #################################################################\n",
        "\n",
        "\n",
        "        ########################## render step ##########################\n",
        "        render_start = time.time() \n",
        "        _, reward, done, _ = env.step(env.actions[action.item()])\n",
        "        render_end = time.time()\n",
        "        #################################################################\n",
        "\n",
        "\n",
        "        ####################### Observe new state #######################\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        last_screen = current_screen\n",
        "        current_screen = get_screen()\n",
        "        if not done:\n",
        "            next_state = current_screen - last_screen\n",
        "        else:\n",
        "            next_state = None\n",
        "        next_state_time = time.time() \n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "        #################################################################\n",
        "\n",
        "\n",
        "        #################################################################\n",
        "        # Perform one step of the optimization (on the target network) ##\n",
        "        optimize_model()\n",
        "        optimize_time = time.time() \n",
        "        #################################################################\n",
        "\n",
        "        if DEBUG:\n",
        "            print(\"step \", t)\n",
        "            print(\"fw time \",fw_end- fw_start)\n",
        "            print(\"render time \", render_end-render_start)\n",
        "            print(\"next state time \", next_state_time- render_end)\n",
        "            print(\"otpimize_time \", optimize_time- next_state_time)\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            break\n",
        "    # Update the target network, copying all weights and biases in DQN\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "    env.close() \n",
        "\n",
        "    # render gameplay video and save model checkpoint\n",
        "    if (i_episode % LOG_VIDEO_EPISODES == 0):\n",
        "        \n",
        "        # Save your model and optimizer\n",
        "        torch.save(policy_net.state_dict(), MODEL_SAVE_NAME+\".pth\")\n",
        "        torch.save(optimizer.state_dict(), OPTIMIZER_SAVE_NAME+\".pth\")\n",
        "        # Save as artifact for version control.\n",
        "        artifact = wandb.Artifact(MODEL_SAVE_NAME, type='model')\n",
        "        artifact.add_file(MODEL_SAVE_NAME+\".pth\")\n",
        "        artifact.add_file(OPTIMIZER_SAVE_NAME+\".pth\")\n",
        "        wandb.log_artifact(artifact)\n",
        "        # run.join()\n",
        "\n",
        "\n",
        "        mp4list = glob.glob('video/*.mp4')\n",
        "        print(mp4list)\n",
        "        if len(mp4list) > 0:\n",
        "            print(len(mp4list))\n",
        "            mp4 = mp4list[-1]\n",
        "            video = io.open(mp4, 'r+b').read()\n",
        "            encoded = base64.b64encode(video)\n",
        "\n",
        "            # log gameplay video in wandb\n",
        "            wandb.log({\"gameplays\": wandb.Video(mp4, fps=4, format=\"gif\")})\n",
        "\n",
        "            # display gameplay video\n",
        "            ipythondisplay.clear_output(wait=True)\n",
        "            ipythondisplay.display(HTML(data='''<video alt=\"\" autoplay \n",
        "                        loop controls style=\"height: 400px;\">\n",
        "                        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "                    </video>'''.format(encoded.decode('ascii'))))\n",
        "            print(\"Episode \",i_episode)\n",
        "\n",
        "print('Complete')\n",
        "# env.render()\n",
        "# env.close()\n",
        "# plt.ioff()\n",
        "# plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"\" autoplay \n",
              "                        loop controls style=\"height: 400px;\">\n",
              "                        <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                    </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Episode  4\n",
            "Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436,
          "referenced_widgets": [
            "d74dbc21f6a74b118728588f03cfbb93",
            "05ec633391c544dc914bb14e0f4b5879",
            "bd9972aaeb154e0d889a035fafad48f8",
            "667ed7b7be5c44d293ab87e798086993",
            "233b81de5b4c46d690ef011db8042583",
            "0e7c3b4c79294ee4ae87407ea0cfe09c",
            "53a0ed84b7dd41e7ae6bb83ae2347bde",
            "583a4db6d9074477b2930a37d49707e6"
          ]
        },
        "id": "c6li-P78pvKN",
        "outputId": "6d2fbf89-24d7-42f0-edaa-d867b9f002bd"
      },
      "source": [
        "wandb.init(resume=WANDB_ID)\n",
        "wandb.run.name = WNDB_NAME\n",
        "\n",
        "# load model\n",
        "model_artifact = wandb.use_artifact(MODEL_SAVE_NAME+':latest', type='model')\n",
        "artifact_dir = model_artifact.download()\n",
        "saved_model = torch.load(artifact_dir+\"/\"+MODEL_SAVE_NAME+\".pth\")\n",
        "saved_optimizer = torch.load(artifact_dir+\"/\"+OPTIMIZER_SAVE_NAME+\".pth\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:sexyid123_new2) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 6392<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d74dbc21f6a74b118728588f03cfbb93",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210219_235345-sexyid123_new2/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210219_235345-sexyid123_new2/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>22077</td></tr><tr><td>_timestamp</td><td>1613778608</td></tr><tr><td>_step</td><td>73</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">Test_bruuuu_new_new2</strong>: <a href=\"https://wandb.ai/andreas_giannoutsos/gym_car_racer/runs/sexyid123_new2\" target=\"_blank\">https://wandb.ai/andreas_giannoutsos/gym_car_racer/runs/sexyid123_new2</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:sexyid123_new2). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.19<br/>\n",
              "                Resuming run <strong style=\"color:#cdcd00\">Test_bruuuu_new_new2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/andreas_giannoutsos/gym_car_racer\" target=\"_blank\">https://wandb.ai/andreas_giannoutsos/gym_car_racer</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/andreas_giannoutsos/gym_car_racer/runs/sexyid123_new2\" target=\"_blank\">https://wandb.ai/andreas_giannoutsos/gym_car_racer/runs/sexyid123_new2</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210220_000136-sexyid123_new2</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_PgrxrfbqVBp",
        "outputId": "5822574b-1d75-4fad-b195-c3c777d041eb"
      },
      "source": [
        "artifact_dir\n",
        "saved_model = torch.load(artifact_dir+\"/\"+MODEL_SAVE_NAME+\".pth\")\n",
        "saved_optimizer = torch.load(artifact_dir+\"/\"+OPTIMIZER_SAVE_NAME+\".pth\")\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./artifacts/DQN_test_model:v0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmPDDxMmoTvA"
      },
      "source": [
        "# env = gnwrapper.Animation(gym.make('CartPole-v1'))\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "# for _ in range(100):\n",
        "#     print(_)\n",
        "#     action = select_action(get_screen())\n",
        "#     next_obs, reward, done, info = env.step(action)\n",
        "#     env.render()\n",
        "\n",
        "#     obs = next_obs\n",
        "#     if done:\n",
        "#         obs = env.reset()\n",
        "#         print(_)\n",
        "total_steps = 0\n",
        "num_episodes = 10\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and state\n",
        "    # env = gnwrapper.Animation(gym.make('CartPole-v1'))\n",
        "    env = gym.make('CartPole-v1')\n",
        "\n",
        "    env.reset()\n",
        "    last_screen = get_screen()\n",
        "    current_screen = get_screen()\n",
        "    state = current_screen - last_screen\n",
        "    print(i_episode)\n",
        "    for t in count():\n",
        "        total_steps+=1\n",
        "        # Select and perform an action\n",
        "        action = select_action(state)\n",
        "        _, reward, done, _ = env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "\n",
        "        # Observe new state\n",
        "        last_screen = current_screen\n",
        "        current_screen = get_screen()\n",
        "        if not done:\n",
        "            next_state = current_screen - last_screen\n",
        "        else:\n",
        "            next_state = None\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            # plot_durations()\n",
        "            break\n",
        "\n",
        "env.close()\n",
        "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
        "           interpolation='none')\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()\n",
        "print(\"total steps \", total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqLIwu80tabc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgvHtGJicRXW"
      },
      "source": [
        "Here is the diagram that illustrates the overall resulting data flow.\n",
        "\n",
        ".. figure:: /_static/img/reinforcement_learning_diagram.jpg\n",
        "\n",
        "Actions are chosen either randomly or based on a policy, getting the next\n",
        "step sample from the gym environment. We record the results in the\n",
        "replay memory and also run optimization step on every iteration.\n",
        "Optimization picks a random batch from the replay memory to do training of the\n",
        "new policy. \"Older\" target_net is also used in optimization to compute the\n",
        "expected Q values; it is updated occasionally to keep it current.\n",
        "\n",
        "\n"
      ]
    }
  ]
}